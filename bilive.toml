# bilive Settings
[model]
model_type = "append" # Can be pipeline, append, merge

# WARNING!: If you choose "deploy" local inference:
# 1. Please check the VRAM requirements twice!
# 2. Please make sure you have installed the Nvidia GPU driver and can check the cuda via `nvcc -V`!
# WARNING!: If you choose "api":
# due to the limitation of free tier, you should keep every video less than 30 minutes(around)
# which means your MODEL_TYPE should not be "merge".
[asr]
asr_method = "none" # can be "deploy" or "api" or "none"
whisper_api_key = "" # Apply for your own API key at https://console.groq.com/keys
inference_model = "small" # If you choose "deploy", you should download the inference model from https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt

[video]
# You can change the title as you like, eg.
title = "{date}直播" # Key words: {artist}, {date}, {title}, {source_link}
description = "录制请征求主播同意，若未经同意就录制，所引起的任何法律问题均由该违规录制的 b 站账号承担。" # Key words: {artist}, {date}, {title}, {source_link}
tid = # The tid of the video(int), see https://bilitool.timerring.com/tid.html
gift_price_filter = 1 # The gift whose price is less than this value will be filtered, unit: RMB
reserve_for_fixing = false # If encounter MOOV crash error, delete the video or reserve for fixing
upload_line = "auto" # The upload line to be used, default None is auto detect(recommended), if you want to specify, it can be "bldsa", "ws", "tx", "qn", "bda2".

[slice]
auto_slice = false # General control: true or false
slice_prompt = "" # Write your own slice prompt here, key word: {artist}
slice_duration = 60 # better not exceed 300 seconds
slice_num = 2 # the number of slices
slice_overlap = 30 # the overlap of slices(seconds) see my package https://github.com/timerring/auto-slice-video for more details
slice_step = 1 # the step of slices(seconds)
min_video_size = 200 # The minimum video size to be sliced (MB)
mllm_model = "qwen" # the multi-model LLMs, can be "qwen" or "gemini" or "zhipu" or "sensenova"
qwen_api_key = "" # Apply for your own Qwen API key at https://bailian.console.aliyun.com/?apiKey=1
zhipu_api_key = "" # Apply for your own GLM-4v-Plus API key at https://www.bigmodel.cn/invite?icode=shBtZUfNE6FfdMH1R6NybGczbXFgPRGIalpycrEwJ28%3D
gemini_api_key = "" # Apply for your own Gemini API key at https://aistudio.google.com/app/apikey
sensenova_api_key = "" # Apply for your own SenseNova API key at https://console.sensecore.cn/aistudio/management/api-key

[cover]
generate_cover = false # whether to generate cover
cover_prompt = "" # Write your own cover prompt here
image_gen_model = "minimax" # the image generation model, can be "minimax" or "siliconflow" or "tencent" or "baidu" or "stability" or "luma" or "ideogram" or "recraft" or "amazon" or "hidream"
minimax_api_key = "" # Apply for your own Minimax API key at https://platform.minimaxi.com/user-center/basic-information/interface-key
siliconflow_api_key = "" # Apply for your own SiliconFlow API key at https://cloud.siliconflow.cn/i/3Szr5BVg
tencent_secret_id = "" # Apply for your own Tencent Cloud API key at https://console.cloud.tencent.com/cam/capi
tencent_secret_key = "" # Apply for your own Tencent Cloud secret key as above
baidu_api_key = "" # Apply for your own Baidu API key at https://console.bce.baidu.com/iam/key/list
stability_api_key = "" # Apply for your own Stability API key at https://platform.stability.ai/account/keys
luma_api_key = "" # Apply for your own Luma API key at https://lumalabs.ai/api/keys
ideogram_api_key = "" # Apply for your own Ideogram API key at https://ideogram.ai/manage-api
recraft_api_key = "" # Apply for your own Recraft API key at https://www.recraft.ai/profile/api
aws_access_key_id = "" # Apply for your own AWS access key id at https://aws.amazon.com/console/
aws_secret_access_key = "" # Apply for your own AWS secret access key as above
hidream_api_key = "" # Apply for your own Hidream API key at https://www.hidreamai.com/platform/token
